{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da035fe58e548e8b1b7e8e89725b9e6bc745aa7b"
   },
   "source": [
    "# Humpback Whale Identification - CNN with Keras\n",
    "This kernel is based on [Anezka Kolaceke](https://www.kaggle.com/anezka)'s awesome work: [CNN with Keras for Humpback Whale ID](https://www.kaggle.com/anezka/cnn-with-keras-for-humpback-whale-id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "0d9c73ad23e6c2eae3028255ee00c3254fe66401"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2cea35de3530cc898be5b85063b84e875401d092"
   },
   "outputs": [],
   "source": [
    "#os.listdir(\"data/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "46a8839e13a14eb8d16ea6823de9927ea63d5001"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the training data\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_whale    9664\n",
       "w_23a388d      73\n",
       "w_9b5109b      65\n",
       "w_9c506f6      62\n",
       "w_0369a5c      61\n",
       "Name: Id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will show the amount of images in some of the categories\n",
    "train_df.Id.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w_23a388d    73\n",
       "w_9b5109b    65\n",
       "w_9c506f6    62\n",
       "w_0369a5c    61\n",
       "w_700ebb4    57\n",
       "Name: Id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the new_whale data points will be removed from the dataframe\n",
    "I_dont_want_new_whales = train_df['Id'] != 'new_whale'\n",
    "train_df = train_df[I_dont_want_new_whales]\n",
    "train_df.Id.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f46b24dbba74f22833cac6140e60348b15a8e047"
   },
   "outputs": [],
   "source": [
    "# this will be used to preprocess the datasets\n",
    "def prepareImages(data, m, dataset):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m, 100, 100, 3))\n",
    "    count = 0\n",
    "    \n",
    "    for fig in data['Image']:\n",
    "        #load images into images of size 100x100x3\n",
    "        img = image.load_img(\"data/\"+dataset+\"/\"+fig, target_size=(100, 100, 3))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        X_train[count] = x\n",
    "        if (count%500 == 0):\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "        count += 1\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "6587a101b58af064af0f9c60a1070c6c8f52d45f"
   },
   "outputs": [],
   "source": [
    "# this will be used to generate labels for the training set\n",
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # print(onehot_encoded)#\n",
    "\n",
    "    y = onehot_encoded\n",
    "    # print(y.shape)\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk of code was added to resolve the error \"OSError: image file is truncated\" in the below cell\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4afe4128a0cd6859848c8a80686208082d647c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  1 ,  0000e88ab.jpg\n",
      "Processing image:  501 ,  0823f9df3.jpg\n",
      "Processing image:  1001 ,  10b694367.jpg\n",
      "Processing image:  1501 ,  195805c52.jpg\n",
      "Processing image:  2001 ,  21e28ae02.jpg\n",
      "Processing image:  2501 ,  2a1146baa.jpg\n",
      "Processing image:  3001 ,  32533a7fb.jpg\n",
      "Processing image:  3501 ,  3a8173905.jpg\n",
      "Processing image:  4001 ,  42f134dea.jpg\n",
      "Processing image:  4501 ,  4aa4de13a.jpg\n",
      "Processing image:  5001 ,  5297b6c40.jpg\n",
      "Processing image:  5501 ,  5b7f0e6e6.jpg\n",
      "Processing image:  6001 ,  6311688b7.jpg\n",
      "Processing image:  6501 ,  6b29760e3.jpg\n",
      "Processing image:  7001 ,  7390cbfab.jpg\n",
      "Processing image:  7501 ,  7b949f512.jpg\n",
      "Processing image:  8001 ,  83336c385.jpg\n",
      "Processing image:  8501 ,  8b369569b.jpg\n",
      "Processing image:  9001 ,  92f450203.jpg\n",
      "Processing image:  9501 ,  9b984102a.jpg\n",
      "Processing image:  10001 ,  a39babc55.jpg\n",
      "Processing image:  10501 ,  ab6f8bddd.jpg\n",
      "Processing image:  11001 ,  b36da6f7c.jpg\n",
      "Processing image:  11501 ,  bb9ffa8b2.jpg\n",
      "Processing image:  12001 ,  c4160ee65.jpg\n",
      "Processing image:  12501 ,  cb7153d51.jpg\n",
      "Processing image:  13001 ,  d3b15e280.jpg\n",
      "Processing image:  13501 ,  dbb2088f4.jpg\n",
      "Processing image:  14001 ,  e3fe27a84.jpg\n",
      "Processing image:  14501 ,  ebde74948.jpg\n",
      "Processing image:  15001 ,  f3f3f8b92.jpg\n",
      "Processing image:  15501 ,  fc54db327.jpg\n"
     ]
    }
   ],
   "source": [
    "# now the training data will be imported\n",
    "X = prepareImages(train_df, train_df.shape[0], \"train\")\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "675924f8863aef27cf90dc668e0a68cd609dfc1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ndurai2006/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y, label_encoder = prepare_labels(train_df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "14d243b19023e830b636bea16679e13bc40deae6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15697, 5004)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "e7af799d186a1b97b6aa325d7d576a1fb55a6c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv0 (Conv2D)               (None, 94, 94, 32)        4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 94, 94, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 94, 94, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 45, 45, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "avg_pool (AveragePooling2D)  (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "rl (Dense)                   (None, 500)               7200500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "sm (Dense)                   (None, 5004)              2507004   \n",
      "=================================================================\n",
      "Total params: 9,730,864\n",
      "Trainable params: 9,730,800\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the CNN will now be defined\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0', input_shape = (100, 100, 3)))\n",
    "\n",
    "model.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), name='max_pool'))\n",
    "model.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D((3, 3), name='avg_pool'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation=\"relu\", name='rl'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(y.shape[1], activation='softmax', name='sm'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "169f45e150c3a584e0f655a8eda523e0675da63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15697/15697 [==============================] - 835s 53ms/step - loss: 8.4461 - acc: 0.0036\n",
      "Epoch 2/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 8.1655 - acc: 0.0039\n",
      "Epoch 3/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 8.0699 - acc: 0.0043\n",
      "Epoch 4/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 7.9804 - acc: 0.0076\n",
      "Epoch 5/100\n",
      "15697/15697 [==============================] - 834s 53ms/step - loss: 7.8581 - acc: 0.0113\n",
      "Epoch 6/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 7.7150 - acc: 0.0143\n",
      "Epoch 7/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 7.5666 - acc: 0.0155\n",
      "Epoch 8/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 7.4100 - acc: 0.0192\n",
      "Epoch 9/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 7.2337 - acc: 0.0234\n",
      "Epoch 10/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 7.0430 - acc: 0.0279\n",
      "Epoch 11/100\n",
      "15697/15697 [==============================] - 830s 53ms/step - loss: 6.8446 - acc: 0.0334\n",
      "Epoch 12/100\n",
      "15697/15697 [==============================] - 830s 53ms/step - loss: 6.6250 - acc: 0.0416\n",
      "Epoch 13/100\n",
      "15697/15697 [==============================] - 830s 53ms/step - loss: 6.3909 - acc: 0.0525\n",
      "Epoch 14/100\n",
      "15697/15697 [==============================] - 828s 53ms/step - loss: 6.1062 - acc: 0.0675\n",
      "Epoch 15/100\n",
      "15697/15697 [==============================] - 829s 53ms/step - loss: 5.8512 - acc: 0.0838\n",
      "Epoch 16/100\n",
      "15697/15697 [==============================] - 828s 53ms/step - loss: 5.5673 - acc: 0.0983\n",
      "Epoch 17/100\n",
      "15697/15697 [==============================] - 828s 53ms/step - loss: 5.3090 - acc: 0.1246\n",
      "Epoch 18/100\n",
      "15697/15697 [==============================] - 829s 53ms/step - loss: 4.9890 - acc: 0.1488\n",
      "Epoch 19/100\n",
      "15697/15697 [==============================] - 828s 53ms/step - loss: 4.7005 - acc: 0.1741\n",
      "Epoch 20/100\n",
      "15697/15697 [==============================] - 828s 53ms/step - loss: 4.4583 - acc: 0.2007\n",
      "Epoch 21/100\n",
      "15697/15697 [==============================] - 829s 53ms/step - loss: 4.2267 - acc: 0.2266\n",
      "Epoch 22/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 3.9760 - acc: 0.2548\n",
      "Epoch 23/100\n",
      "15697/15697 [==============================] - 830s 53ms/step - loss: 3.7220 - acc: 0.2908\n",
      "Epoch 24/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 3.4848 - acc: 0.3169\n",
      "Epoch 25/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 3.3138 - acc: 0.3410\n",
      "Epoch 26/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 3.1137 - acc: 0.3661\n",
      "Epoch 27/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 2.9214 - acc: 0.3931\n",
      "Epoch 28/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 2.7489 - acc: 0.4196\n",
      "Epoch 29/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 2.6554 - acc: 0.4351\n",
      "Epoch 30/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 2.5297 - acc: 0.4538\n",
      "Epoch 31/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 2.3467 - acc: 0.4839\n",
      "Epoch 32/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 2.2525 - acc: 0.4973\n",
      "Epoch 33/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 2.1512 - acc: 0.5173\n",
      "Epoch 34/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 2.1054 - acc: 0.5277\n",
      "Epoch 35/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 1.9589 - acc: 0.5488\n",
      "Epoch 36/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 1.8943 - acc: 0.5639\n",
      "Epoch 37/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 1.8346 - acc: 0.5786\n",
      "Epoch 38/100\n",
      "15697/15697 [==============================] - 829s 53ms/step - loss: 1.7539 - acc: 0.5865\n",
      "Epoch 39/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 1.7008 - acc: 0.5978\n",
      "Epoch 40/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 1.6520 - acc: 0.6117\n",
      "Epoch 41/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 1.5999 - acc: 0.6208\n",
      "Epoch 42/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 1.5196 - acc: 0.6366\n",
      "Epoch 43/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 1.4903 - acc: 0.6416\n",
      "Epoch 44/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 1.4054 - acc: 0.6593\n",
      "Epoch 45/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 1.3939 - acc: 0.6567\n",
      "Epoch 46/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 1.3461 - acc: 0.6721\n",
      "Epoch 47/100\n",
      "15697/15697 [==============================] - 830s 53ms/step - loss: 1.3379 - acc: 0.6714\n",
      "Epoch 48/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 1.2827 - acc: 0.6794\n",
      "Epoch 49/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 1.2236 - acc: 0.6945\n",
      "Epoch 50/100\n",
      "15697/15697 [==============================] - 831s 53ms/step - loss: 1.2110 - acc: 0.6960\n",
      "Epoch 51/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 1.1800 - acc: 0.7073\n",
      "Epoch 52/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 1.1489 - acc: 0.7071\n",
      "Epoch 53/100\n",
      "15697/15697 [==============================] - 837s 53ms/step - loss: 1.1322 - acc: 0.7184\n",
      "Epoch 54/100\n",
      "15697/15697 [==============================] - 842s 54ms/step - loss: 1.1357 - acc: 0.7129\n",
      "Epoch 55/100\n",
      "15697/15697 [==============================] - 844s 54ms/step - loss: 1.0937 - acc: 0.7226\n",
      "Epoch 56/100\n",
      "15697/15697 [==============================] - 842s 54ms/step - loss: 1.0480 - acc: 0.7305\n",
      "Epoch 57/100\n",
      "15697/15697 [==============================] - 844s 54ms/step - loss: 1.0096 - acc: 0.7409\n",
      "Epoch 58/100\n",
      "15697/15697 [==============================] - 845s 54ms/step - loss: 1.0265 - acc: 0.7373\n",
      "Epoch 59/100\n",
      "15697/15697 [==============================] - 844s 54ms/step - loss: 1.0036 - acc: 0.7428\n",
      "Epoch 60/100\n",
      "15697/15697 [==============================] - 841s 54ms/step - loss: 0.9780 - acc: 0.7514\n",
      "Epoch 61/100\n",
      "15697/15697 [==============================] - 843s 54ms/step - loss: 0.9637 - acc: 0.7538\n",
      "Epoch 62/100\n",
      "15697/15697 [==============================] - 839s 53ms/step - loss: 0.9266 - acc: 0.7610\n",
      "Epoch 63/100\n",
      "15697/15697 [==============================] - 830s 53ms/step - loss: 0.9394 - acc: 0.7596\n",
      "Epoch 64/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 0.9101 - acc: 0.7622\n",
      "Epoch 65/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 0.9170 - acc: 0.7608\n",
      "Epoch 66/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 0.8982 - acc: 0.7672\n",
      "Epoch 67/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 0.8717 - acc: 0.7728\n",
      "Epoch 68/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 0.8559 - acc: 0.7756\n",
      "Epoch 69/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 0.8310 - acc: 0.7795\n",
      "Epoch 70/100\n",
      "15697/15697 [==============================] - 834s 53ms/step - loss: 0.8466 - acc: 0.7766\n",
      "Epoch 71/100\n",
      "15697/15697 [==============================] - 836s 53ms/step - loss: 0.8291 - acc: 0.7830\n",
      "Epoch 72/100\n",
      "15697/15697 [==============================] - 832s 53ms/step - loss: 0.8102 - acc: 0.7893\n",
      "Epoch 73/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 0.8001 - acc: 0.7886\n",
      "Epoch 74/100\n",
      "15697/15697 [==============================] - 842s 54ms/step - loss: 0.7747 - acc: 0.7940\n",
      "Epoch 75/100\n",
      "15697/15697 [==============================] - 843s 54ms/step - loss: 0.7749 - acc: 0.7960\n",
      "Epoch 76/100\n",
      "15697/15697 [==============================] - 842s 54ms/step - loss: 0.7751 - acc: 0.7939\n",
      "Epoch 77/100\n",
      "15697/15697 [==============================] - 843s 54ms/step - loss: 0.7292 - acc: 0.8053\n",
      "Epoch 78/100\n",
      "15697/15697 [==============================] - 842s 54ms/step - loss: 0.7592 - acc: 0.8003\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15697/15697 [==============================] - 844s 54ms/step - loss: 0.7360 - acc: 0.8063\n",
      "Epoch 80/100\n",
      "15697/15697 [==============================] - 846s 54ms/step - loss: 0.7230 - acc: 0.8074\n",
      "Epoch 81/100\n",
      "15697/15697 [==============================] - 844s 54ms/step - loss: 0.7306 - acc: 0.8051\n",
      "Epoch 82/100\n",
      "15697/15697 [==============================] - 843s 54ms/step - loss: 0.7157 - acc: 0.8073\n",
      "Epoch 83/100\n",
      "15697/15697 [==============================] - 842s 54ms/step - loss: 0.7225 - acc: 0.8101\n",
      "Epoch 84/100\n",
      "15697/15697 [==============================] - 844s 54ms/step - loss: 0.7183 - acc: 0.8075\n",
      "Epoch 85/100\n",
      "15697/15697 [==============================] - 843s 54ms/step - loss: 0.6766 - acc: 0.8191\n",
      "Epoch 86/100\n",
      "15697/15697 [==============================] - 846s 54ms/step - loss: 0.6740 - acc: 0.8209\n",
      "Epoch 87/100\n",
      "15697/15697 [==============================] - 844s 54ms/step - loss: 0.6654 - acc: 0.8206\n",
      "Epoch 88/100\n",
      "15697/15697 [==============================] - 845s 54ms/step - loss: 0.6607 - acc: 0.8242\n",
      "Epoch 89/100\n",
      "15697/15697 [==============================] - 846s 54ms/step - loss: 0.6596 - acc: 0.8226\n",
      "Epoch 90/100\n",
      "15697/15697 [==============================] - 845s 54ms/step - loss: 0.6247 - acc: 0.8294\n",
      "Epoch 91/100\n",
      "15697/15697 [==============================] - 844s 54ms/step - loss: 0.6325 - acc: 0.8307\n",
      "Epoch 92/100\n",
      "15697/15697 [==============================] - 840s 53ms/step - loss: 0.6139 - acc: 0.8344\n",
      "Epoch 93/100\n",
      "15697/15697 [==============================] - 841s 54ms/step - loss: 0.6012 - acc: 0.8359\n",
      "Epoch 94/100\n",
      "15697/15697 [==============================] - 833s 53ms/step - loss: 0.6327 - acc: 0.8321\n",
      "Epoch 95/100\n",
      "15697/15697 [==============================] - 839s 53ms/step - loss: 0.6282 - acc: 0.8305\n",
      "Epoch 96/100\n",
      "15697/15697 [==============================] - 842s 54ms/step - loss: 0.6098 - acc: 0.8330\n",
      "Epoch 97/100\n",
      "15697/15697 [==============================] - 842s 54ms/step - loss: 0.5928 - acc: 0.8363\n",
      "Epoch 98/100\n",
      "15697/15697 [==============================] - 841s 54ms/step - loss: 0.5800 - acc: 0.8449\n",
      "Epoch 99/100\n",
      "15697/15697 [==============================] - 843s 54ms/step - loss: 0.6235 - acc: 0.8334\n",
      "Epoch 100/100\n",
      "15697/15697 [==============================] - 841s 54ms/step - loss: 0.5816 - acc: 0.8373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9240"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will train the CNN\n",
    "history = model.fit(X, y, epochs=100, batch_size=100, verbose=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "7bca48a1d0963cbf70685b75431435cef9499895"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This will plot the accuracy of the CNN on the training set after each epoch\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  1 ,  0000e88ab.jpg\n",
      "Processing image:  501 ,  04c72257b.jpg\n",
      "Processing image:  1001 ,  09cacb84d.jpg\n",
      "Processing image:  1501 ,  0ef961892.jpg\n",
      "Processing image:  2001 ,  141b56a1a.jpg\n",
      "Processing image:  2501 ,  199a417aa.jpg\n",
      "Processing image:  3001 ,  1ec170983.jpg\n",
      "Processing image:  3501 ,  23f084b93.jpg\n",
      "Processing image:  4001 ,  29163ad0b.jpg\n",
      "Processing image:  4501 ,  2e0fab120.jpg\n",
      "Processing image:  5001 ,  3347515d9.jpg\n",
      "Processing image:  5501 ,  3842d71dc.jpg\n",
      "Processing image:  6001 ,  3d7f4c7d5.jpg\n",
      "Processing image:  6501 ,  425f763ca.jpg\n",
      "Processing image:  7001 ,  4714400cd.jpg\n",
      "Processing image:  7501 ,  4c082fbdf.jpg\n",
      "Processing image:  8001 ,  50c683e23.jpg\n",
      "Processing image:  8501 ,  560d986ad.jpg\n",
      "Processing image:  9001 ,  5b68c83ed.jpg\n",
      "Processing image:  9501 ,  60410f111.jpg\n",
      "Processing image:  10001 ,  654951f81.jpg\n",
      "Processing image:  10501 ,  6a572256c.jpg\n",
      "Processing image:  11001 ,  6f96f55b6.jpg\n",
      "Processing image:  11501 ,  74da2b511.jpg\n",
      "Processing image:  12001 ,  7989d9a27.jpg\n",
      "Processing image:  12501 ,  7e5aa2d8a.jpg\n",
      "Processing image:  13001 ,  832382cfb.jpg\n",
      "Processing image:  13501 ,  87f6c0a15.jpg\n",
      "Processing image:  14001 ,  8cfc22e5d.jpg\n",
      "Processing image:  14501 ,  91dcfedcd.jpg\n",
      "Processing image:  15001 ,  97079398e.jpg\n",
      "Processing image:  15501 ,  9c2ad64a9.jpg\n",
      "Processing image:  16001 ,  a11956dff.jpg\n",
      "Processing image:  16501 ,  a5f9ffe86.jpg\n",
      "Processing image:  17001 ,  aaf1a967b.jpg\n",
      "Processing image:  17501 ,  af9a1ffc6.jpg\n",
      "Processing image:  18001 ,  b4e02531d.jpg\n",
      "Processing image:  18501 ,  ba2355ca6.jpg\n",
      "Processing image:  19001 ,  bf60e7fed.jpg\n",
      "Processing image:  19501 ,  c49f39ce3.jpg\n",
      "Processing image:  20001 ,  c960111d0.jpg\n",
      "Processing image:  20501 ,  ce7984d8a.jpg\n",
      "Processing image:  21001 ,  d38efaec9.jpg\n",
      "Processing image:  21501 ,  d831d28ee.jpg\n",
      "Processing image:  22001 ,  dd3ca2387.jpg\n",
      "Processing image:  22501 ,  e288d66cf.jpg\n",
      "Processing image:  23001 ,  e7cc793db.jpg\n",
      "Processing image:  23501 ,  ec8c7229d.jpg\n",
      "Processing image:  24001 ,  f1b850552.jpg\n",
      "Processing image:  24501 ,  f6af8a4b8.jpg\n",
      "Processing image:  25001 ,  fc09f2302.jpg\n"
     ]
    }
   ],
   "source": [
    "# Now an optimal threshold for the new_whale label will be determined.\n",
    "# First the entire training set (includeing new_whales) will be imported\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "X = prepareImages(train_df, train_df.shape[0], \"train\")\n",
    "X /= 255\n",
    "y = train_df['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25361/25361 [==============================] - 561s 22ms/step\n",
      "Threshold = 0.100, MAP5 = 0.842\n",
      "Threshold = 0.110, MAP5 = 0.853\n",
      "Threshold = 0.120, MAP5 = 0.862\n",
      "Threshold = 0.130, MAP5 = 0.870\n",
      "Threshold = 0.140, MAP5 = 0.877\n",
      "Threshold = 0.150, MAP5 = 0.883\n",
      "Threshold = 0.160, MAP5 = 0.888\n",
      "Threshold = 0.170, MAP5 = 0.893\n",
      "Threshold = 0.180, MAP5 = 0.898\n",
      "Threshold = 0.190, MAP5 = 0.902\n",
      "Threshold = 0.200, MAP5 = 0.906\n",
      "Threshold = 0.210, MAP5 = 0.910\n",
      "Threshold = 0.220, MAP5 = 0.913\n",
      "Threshold = 0.230, MAP5 = 0.916\n",
      "Threshold = 0.240, MAP5 = 0.919\n",
      "Threshold = 0.250, MAP5 = 0.923\n",
      "Threshold = 0.260, MAP5 = 0.925\n",
      "Threshold = 0.270, MAP5 = 0.928\n",
      "Threshold = 0.280, MAP5 = 0.930\n",
      "Threshold = 0.290, MAP5 = 0.932\n",
      "Threshold = 0.300, MAP5 = 0.934\n",
      "Threshold = 0.310, MAP5 = 0.936\n",
      "Threshold = 0.320, MAP5 = 0.938\n",
      "Threshold = 0.330, MAP5 = 0.940\n",
      "Threshold = 0.340, MAP5 = 0.941\n",
      "Threshold = 0.350, MAP5 = 0.943\n",
      "Threshold = 0.360, MAP5 = 0.945\n",
      "Threshold = 0.370, MAP5 = 0.946\n",
      "Threshold = 0.380, MAP5 = 0.948\n",
      "Threshold = 0.390, MAP5 = 0.949\n",
      "Threshold = 0.400, MAP5 = 0.951\n",
      "Threshold = 0.410, MAP5 = 0.952\n",
      "Threshold = 0.420, MAP5 = 0.953\n",
      "Threshold = 0.430, MAP5 = 0.954\n",
      "Threshold = 0.440, MAP5 = 0.955\n",
      "Threshold = 0.450, MAP5 = 0.957\n",
      "Threshold = 0.460, MAP5 = 0.958\n",
      "Threshold = 0.470, MAP5 = 0.959\n",
      "Threshold = 0.480, MAP5 = 0.960\n",
      "Threshold = 0.490, MAP5 = 0.961\n",
      "Threshold = 0.500, MAP5 = 0.962\n",
      "Threshold = 0.510, MAP5 = 0.963\n",
      "Threshold = 0.520, MAP5 = 0.964\n",
      "Threshold = 0.530, MAP5 = 0.965\n",
      "Threshold = 0.540, MAP5 = 0.966\n",
      "Threshold = 0.550, MAP5 = 0.967\n",
      "Threshold = 0.560, MAP5 = 0.967\n",
      "Threshold = 0.570, MAP5 = 0.968\n",
      "Threshold = 0.580, MAP5 = 0.969\n",
      "Threshold = 0.590, MAP5 = 0.970\n",
      "Threshold = 0.600, MAP5 = 0.971\n",
      "Threshold = 0.610, MAP5 = 0.972\n",
      "Threshold = 0.620, MAP5 = 0.973\n",
      "Threshold = 0.630, MAP5 = 0.973\n",
      "Threshold = 0.640, MAP5 = 0.974\n",
      "Threshold = 0.650, MAP5 = 0.975\n",
      "Threshold = 0.660, MAP5 = 0.975\n",
      "Threshold = 0.670, MAP5 = 0.976\n",
      "Threshold = 0.680, MAP5 = 0.977\n",
      "Threshold = 0.690, MAP5 = 0.977\n",
      "Threshold = 0.700, MAP5 = 0.978\n",
      "Threshold = 0.710, MAP5 = 0.979\n",
      "Threshold = 0.720, MAP5 = 0.980\n",
      "Threshold = 0.730, MAP5 = 0.980\n",
      "Threshold = 0.740, MAP5 = 0.981\n",
      "Threshold = 0.750, MAP5 = 0.981\n",
      "Threshold = 0.760, MAP5 = 0.982\n",
      "Threshold = 0.770, MAP5 = 0.983\n",
      "Threshold = 0.780, MAP5 = 0.983\n",
      "Threshold = 0.790, MAP5 = 0.984\n",
      "Threshold = 0.800, MAP5 = 0.984\n",
      "Threshold = 0.810, MAP5 = 0.985\n",
      "Threshold = 0.820, MAP5 = 0.986\n",
      "Threshold = 0.830, MAP5 = 0.986\n",
      "Threshold = 0.840, MAP5 = 0.987\n",
      "Threshold = 0.850, MAP5 = 0.987\n",
      "Threshold = 0.860, MAP5 = 0.988\n",
      "Threshold = 0.870, MAP5 = 0.988\n",
      "Threshold = 0.880, MAP5 = 0.989\n",
      "Threshold = 0.890, MAP5 = 0.990\n",
      "Threshold = 0.900, MAP5 = 0.990\n"
     ]
    }
   ],
   "source": [
    "# the map5 function will be used to evaluate the predictions\n",
    "def map5(X, y):\n",
    "    score = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        pred = X[i]\n",
    "        lp = label_encoder.inverse_transform(pred.argsort()[-5:][::-1])\n",
    "        p2 = pred[:]\n",
    "        ind = pred.argsort()[-5:][::-1]\n",
    "        s = sum(p2[ind] < th)\n",
    "        if s != 0:\n",
    "            for j in range(lp.size):\n",
    "                if p2[ind[j]] < th:\n",
    "                    k = j\n",
    "                    lp[k] = 'new_whale'\n",
    "                    break\n",
    "# the below line is commented to avoid the error \"UnboundLocalError: local variable 'k' referenced before assignment\"\n",
    "#            lp[k] = 'new_whale'\n",
    "        #pred = X[i].argsort()[-5:][::-1]\n",
    "        for j in range(lp.size):\n",
    "            if lp[j] == y[i]:\n",
    "                score += (5 - j)/5\n",
    "                break\n",
    "    return score/X.shape[0]\n",
    "\n",
    "# now the optimal threshold will be determined by calculating the map5 score for each threshold value.\n",
    "predictions = model.predict(np.array(X), verbose=1)\n",
    "best_th = 0\n",
    "best_score = 0\n",
    "for th in np.arange(0.1, 0.91, 0.01):\n",
    "    #predictions[:,0] = th\n",
    "    score = map5(predictions, y)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_th = th\n",
    "    print(\"Threshold = {:.3f}, MAP5 = {:.3f}\".format(th,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "debe961c93b72bef151d9aad3ca2cb500ee00aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7960\n"
     ]
    }
   ],
   "source": [
    "# now the predictions for the test data can be made\n",
    "test = os.listdir(\"data/test\")\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "72ed8198f519f7b1ae3efbc688933c78d8cdd0e4"
   },
   "outputs": [],
   "source": [
    "# a new column that will contain the five predictions will be made\n",
    "col = ['Image']\n",
    "test_df = pd.DataFrame(test, columns=col)\n",
    "test_df['Id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "52262195fc0b8755cff78bf8c98e6116d50f79af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n",
      "Processing image:  1 ,  bfd521ee0.jpg\n",
      "Processing image:  501 ,  f124e20f9.jpg\n",
      "Processing image:  1001 ,  7fd675d90.jpg\n",
      "Processing image:  1501 ,  f15cc97a7.jpg\n",
      "Processing image:  2001 ,  b0ced16b2.jpg\n",
      "Processing image:  2501 ,  5b8f3af0a.jpg\n",
      "Processing image:  3001 ,  00ccb53ec.jpg\n",
      "Processing image:  3501 ,  378f63826.jpg\n",
      "Processing image:  4001 ,  a8e72eb20.jpg\n",
      "Processing image:  4501 ,  599fb6ecf.jpg\n",
      "Processing image:  5001 ,  292b2b27d.jpg\n",
      "Processing image:  5501 ,  2aeee8b9f.jpg\n",
      "Processing image:  6001 ,  ea046b98d.jpg\n",
      "Processing image:  6501 ,  43e35c1b6.jpg\n",
      "Processing image:  7001 ,  e67b3fc69.jpg\n",
      "Processing image:  7501 ,  bc605917b.jpg\n"
     ]
    }
   ],
   "source": [
    "# this will preprocess the test data\n",
    "X = prepareImages(test_df, test_df.shape[0], \"test\")\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "88c8d8ff98fbdb1df4218abb6bd51889e855a6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7960/7960 [==============================] - 174s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "# now the labels for the test data will be generated\n",
    "predictions = model.predict(np.array(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "66f0bdde31b8c7847916268aa82d9a1bdc9c0658"
   },
   "outputs": [],
   "source": [
    "# best_th = 0.01 # only run this line if you did not determine the optimal threshold\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    lp = label_encoder.inverse_transform(pred.argsort()[-5:][::-1])\n",
    "    p2 = pred[:]\n",
    "    ind = pred.argsort()[-5:][::-1]\n",
    "    s = sum(p2[ind] < best_th)\n",
    "    if s != 0:\n",
    "        for j in range(lp.size):\n",
    "            if p2[ind[j]] < best_th:\n",
    "                k = j\n",
    "                lp[k] = 'new_whale'\n",
    "                break\n",
    "#        lp[k] = 'new_whale'\n",
    "    test_df.loc[i, 'Id'] = ' '.join(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "09d7c1eb9b554e4e580b0c3c7eb609c15636892d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Image                                                 Id\n",
      "0  bfd521ee0.jpg  new_whale w_f6c5343 w_564a34b w_59052ad w_f829227\n",
      "1  02b063a20.jpg  new_whale w_9ba4a9a w_700ebb4 w_cd4cb49 w_53215c6\n",
      "2  48dc51d2a.jpg  new_whale w_89f6097 w_23a388d w_1f0cf0a w_a9304b9\n",
      "3  f553318b3.jpg  new_whale w_a586dce w_3bf2653 w_f765256 w_eba33fb\n",
      "4  1546729ec.jpg  new_whale w_700ebb4 w_67153b4 w_f765256 w_51fc1fc\n",
      "5  8cc48ab02.jpg  new_whale w_23a388d w_c25d2d1 w_cb4182e w_6cda039\n",
      "6  de74478c6.jpg  new_whale w_a9304b9 w_53215c6 w_9b5109b w_4a28f21\n",
      "7  211d8987b.jpg  new_whale w_16df050 w_700ebb4 w_a9304b9 w_0369a5c\n",
      "8  b0675b37a.jpg  new_whale w_0369a5c w_343f088 w_aa32f70 w_9b5109b\n",
      "9  8c10e784e.jpg  new_whale w_cd4cb49 w_d405854 w_0369a5c w_8193215\n"
     ]
    }
   ],
   "source": [
    "# now the predictions will be saved in a csv file which can be submitted\n",
    "print(test_df.head(10))\n",
    "test_df.to_csv(\"data/submission_v5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## IGNORE THE REMAINING CODE BLOCKS!!!! #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv(\"data/train.csv\")\n",
    "#X = prepareImages(train_df, train_df.shape[0], \"train\")\n",
    "#X /= 255\n",
    "#y, label_encoder = prepare_labels(train_df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict(np.array(X), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#th = 0.5\n",
    "#m = map5(predictions,y)\n",
    "#print('score:'+ str(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predictions[0].argsort()[-5:][::-1])\n",
    "#p2 = predictions[0]\n",
    "#p2 = p2[:]\n",
    "#ind = np.argpartition(p2, -5)[-5:]\n",
    "#lp = label_encoder.inverse_transform(predictions[0].argsort()[-5:][::-1])\n",
    "#print(lp.size)\n",
    "#print(p2)\n",
    "#print(ind)\n",
    "#print(p2[ind])\n",
    "#p3 = predictions[0].argsort()[-5:][::-1]\n",
    "#print(p3)\n",
    "#print(predictions[0][p3])\n",
    "#for i in range(5):\n",
    "#    lp = label_encoder.inverse_transform(predictions[i].argsort()[-5:][::-1])\n",
    "#    print(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
